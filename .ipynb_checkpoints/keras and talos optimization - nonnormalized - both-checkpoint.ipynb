{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "c:\\users\\sammour\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\users\\sammour\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\users\\sammour\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\users\\sammour\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\users\\sammour\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\users\\sammour\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "c:\\users\\sammour\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\users\\sammour\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\users\\sammour\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\users\\sammour\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\users\\sammour\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\users\\sammour\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Dense\n",
    "from sklearn.datasets import make_regression\n",
    "from talos.utils import hidden_layers\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "import talos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#china dataset that doesn't work\n",
    "df = pd.read_csv(\"preproc.csv\") \n",
    "train, test = train_test_split(df, test_size=0.2)\n",
    "train = train.drop(['Date','1d'], axis = 1)\n",
    "test = test.drop(['Date','1d'], axis = 1)\n",
    "\n",
    "train_y = train[train.columns[1]].values\n",
    "train_x = train.drop(['PM2.5'], axis = 1).values\n",
    "\n",
    "test_y = test[test.columns[1]].values\n",
    "test_x = test.drop(['PM2.5'], axis = 1).values\n",
    "\n",
    "#normalizer = MinMaxScaler(feature_range = (0, 1))\n",
    "#train_x = normalizer.fit_transform(train_x)\n",
    "#test_x = normalizer.fit_transform(test_x)\n",
    "\n",
    "#train_y = train_y.reshape(-1, 1)\n",
    "#train_y = normalizer.fit_transform(train_y)\n",
    "#test_y = test_y.reshape(-1, 1)\n",
    "#test_y = normalizer.fit_transform(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#base = pd.read_csv('PRSA_data_2010.1.1-2014.12.31.csv')\n",
    "#base = base.dropna()\n",
    "#base = base.drop('No', axis = 1)\n",
    "#base = base.drop('year', axis = 1)\n",
    "#base = base.drop('month', axis = 1)\n",
    "#base = base.drop('day', axis = 1)\n",
    "#base = base.drop('hour', axis = 1)\n",
    "#base = base.drop('cbwd', axis = 1)\n",
    "\n",
    "#train = base.iloc[:, 1:7].values\n",
    "#target = base.iloc[:, 0].values\n",
    "\n",
    "#normalizador = MinMaxScaler(feature_range = (0, 1))\n",
    "#train = normalizador.fit_transform(train)\n",
    "\n",
    "#target = target.reshape(-1, 1)\n",
    "#target = normalizador.fit_transform(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we have to make sure to input data and params into the function\n",
    "def create_model(x_train, y_train, x_val, y_val, params):\n",
    "\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Add first hidden layer with input_dim of input features\n",
    "    model.add(Dense(params['number_of_neurons'], input_dim=x_train.shape[1],\n",
    "                    activation=params['activation'],\n",
    "                    kernel_initializer=params['kernel_initializer']))\n",
    "    \n",
    "    # Add second hidden layer\n",
    "    model.add(Dense(params['number_of_neurons'],\n",
    "                    activation=params['activation'],\n",
    "                    kernel_initializer=params['kernel_initializer']))\n",
    "    \n",
    "    # Add final layer with a linear activation function\n",
    "    model.add(Dense(1, activation=params['last_activation'],\n",
    "                    kernel_initializer=params['kernel_initializer']))\n",
    "    \n",
    "    # Compile neural network\n",
    "    model.compile(loss=params['losses'],\n",
    "                  optimizer=params['optimizer'],\n",
    "                  metrics=['mae'])\n",
    "    \n",
    "    history = model.fit(x_train, y_train, \n",
    "                        validation_data=[x_val, y_val],\n",
    "                        batch_size=params['batch_size'],\n",
    "                        callbacks=[talos.utils.live()],\n",
    "                        epochs=params['epochs'],\n",
    "                        verbose=0)\n",
    "\n",
    "    return history, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# then we can go ahead and set the parameter space\n",
    "p = {'number_of_neurons':[1,25,50,75,100,125,150],\n",
    "     'lr': [0.01,0.00001,0.0001,0.001,0.3,1],\n",
    "     'batch_size': [30],\n",
    "     'epochs': [100],\n",
    "     'dropout': [0],\n",
    "     'kernel_initializer': ['uniform'],\n",
    "     'optimizer': ['Adam'],\n",
    "     'losses': ['mae'],\n",
    "     'activation':['relu'],\n",
    "     'last_activation': ['linear']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 42/42 [50:00<00:00, 71.45s/it]\n"
     ]
    }
   ],
   "source": [
    "# and run the experiment\n",
    "t = talos.Scan(x=train_x,\n",
    "               y=train_y,\n",
    "               model=create_model,\n",
    "               params=p,\n",
    "               experiment_name='nonnormalized-both')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>round_epochs</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_mae</th>\n",
       "      <th>loss</th>\n",
       "      <th>mae</th>\n",
       "      <th>activation</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>dropout</th>\n",
       "      <th>epochs</th>\n",
       "      <th>kernel_initializer</th>\n",
       "      <th>last_activation</th>\n",
       "      <th>losses</th>\n",
       "      <th>lr</th>\n",
       "      <th>number_of_neurons</th>\n",
       "      <th>optimizer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>54.658017</td>\n",
       "      <td>54.658028</td>\n",
       "      <td>55.451676</td>\n",
       "      <td>55.451672</td>\n",
       "      <td>relu</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>uniform</td>\n",
       "      <td>linear</td>\n",
       "      <td>mae</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>1</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>47.030283</td>\n",
       "      <td>47.030293</td>\n",
       "      <td>47.435449</td>\n",
       "      <td>47.435455</td>\n",
       "      <td>relu</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>uniform</td>\n",
       "      <td>linear</td>\n",
       "      <td>mae</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>25</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>46.621623</td>\n",
       "      <td>46.621613</td>\n",
       "      <td>47.053209</td>\n",
       "      <td>47.053215</td>\n",
       "      <td>relu</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>uniform</td>\n",
       "      <td>linear</td>\n",
       "      <td>mae</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>50</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>47.006439</td>\n",
       "      <td>47.006439</td>\n",
       "      <td>46.999699</td>\n",
       "      <td>46.999691</td>\n",
       "      <td>relu</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>uniform</td>\n",
       "      <td>linear</td>\n",
       "      <td>mae</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>75</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100</td>\n",
       "      <td>46.342011</td>\n",
       "      <td>46.341999</td>\n",
       "      <td>47.275445</td>\n",
       "      <td>47.275444</td>\n",
       "      <td>relu</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>uniform</td>\n",
       "      <td>linear</td>\n",
       "      <td>mae</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>100</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100</td>\n",
       "      <td>45.980314</td>\n",
       "      <td>45.980309</td>\n",
       "      <td>47.204249</td>\n",
       "      <td>47.204239</td>\n",
       "      <td>relu</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>uniform</td>\n",
       "      <td>linear</td>\n",
       "      <td>mae</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>125</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>100</td>\n",
       "      <td>46.357134</td>\n",
       "      <td>46.357128</td>\n",
       "      <td>46.871089</td>\n",
       "      <td>46.871086</td>\n",
       "      <td>relu</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>uniform</td>\n",
       "      <td>linear</td>\n",
       "      <td>mae</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>150</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>100</td>\n",
       "      <td>54.656627</td>\n",
       "      <td>54.656628</td>\n",
       "      <td>55.450429</td>\n",
       "      <td>55.450428</td>\n",
       "      <td>relu</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>uniform</td>\n",
       "      <td>linear</td>\n",
       "      <td>mae</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>1</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>100</td>\n",
       "      <td>46.864199</td>\n",
       "      <td>46.864208</td>\n",
       "      <td>47.167210</td>\n",
       "      <td>47.167206</td>\n",
       "      <td>relu</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>uniform</td>\n",
       "      <td>linear</td>\n",
       "      <td>mae</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>25</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>100</td>\n",
       "      <td>46.522723</td>\n",
       "      <td>46.522717</td>\n",
       "      <td>47.101156</td>\n",
       "      <td>47.101143</td>\n",
       "      <td>relu</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>uniform</td>\n",
       "      <td>linear</td>\n",
       "      <td>mae</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>50</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>100</td>\n",
       "      <td>47.086224</td>\n",
       "      <td>47.086224</td>\n",
       "      <td>47.139988</td>\n",
       "      <td>47.139999</td>\n",
       "      <td>relu</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>uniform</td>\n",
       "      <td>linear</td>\n",
       "      <td>mae</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>75</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>100</td>\n",
       "      <td>47.163597</td>\n",
       "      <td>47.163589</td>\n",
       "      <td>46.800133</td>\n",
       "      <td>46.800137</td>\n",
       "      <td>relu</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>uniform</td>\n",
       "      <td>linear</td>\n",
       "      <td>mae</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>100</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>100</td>\n",
       "      <td>46.608718</td>\n",
       "      <td>46.608711</td>\n",
       "      <td>47.031423</td>\n",
       "      <td>47.031422</td>\n",
       "      <td>relu</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>uniform</td>\n",
       "      <td>linear</td>\n",
       "      <td>mae</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>125</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>100</td>\n",
       "      <td>46.194201</td>\n",
       "      <td>46.194187</td>\n",
       "      <td>46.797180</td>\n",
       "      <td>46.797192</td>\n",
       "      <td>relu</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>uniform</td>\n",
       "      <td>linear</td>\n",
       "      <td>mae</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>150</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>100</td>\n",
       "      <td>54.660783</td>\n",
       "      <td>54.660763</td>\n",
       "      <td>55.454871</td>\n",
       "      <td>55.454868</td>\n",
       "      <td>relu</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>uniform</td>\n",
       "      <td>linear</td>\n",
       "      <td>mae</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>1</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>100</td>\n",
       "      <td>47.190145</td>\n",
       "      <td>47.190147</td>\n",
       "      <td>47.520032</td>\n",
       "      <td>47.520046</td>\n",
       "      <td>relu</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>uniform</td>\n",
       "      <td>linear</td>\n",
       "      <td>mae</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>25</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>100</td>\n",
       "      <td>47.591563</td>\n",
       "      <td>47.591564</td>\n",
       "      <td>47.440702</td>\n",
       "      <td>47.440701</td>\n",
       "      <td>relu</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>uniform</td>\n",
       "      <td>linear</td>\n",
       "      <td>mae</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>50</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>100</td>\n",
       "      <td>47.046996</td>\n",
       "      <td>47.046982</td>\n",
       "      <td>47.011675</td>\n",
       "      <td>47.011669</td>\n",
       "      <td>relu</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>uniform</td>\n",
       "      <td>linear</td>\n",
       "      <td>mae</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>75</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>100</td>\n",
       "      <td>46.411512</td>\n",
       "      <td>46.411503</td>\n",
       "      <td>47.047215</td>\n",
       "      <td>47.047218</td>\n",
       "      <td>relu</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>uniform</td>\n",
       "      <td>linear</td>\n",
       "      <td>mae</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>100</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>100</td>\n",
       "      <td>45.946016</td>\n",
       "      <td>45.946011</td>\n",
       "      <td>46.870604</td>\n",
       "      <td>46.870609</td>\n",
       "      <td>relu</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>uniform</td>\n",
       "      <td>linear</td>\n",
       "      <td>mae</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>125</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>100</td>\n",
       "      <td>46.237721</td>\n",
       "      <td>46.237732</td>\n",
       "      <td>47.270942</td>\n",
       "      <td>47.270962</td>\n",
       "      <td>relu</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>uniform</td>\n",
       "      <td>linear</td>\n",
       "      <td>mae</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>150</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>100</td>\n",
       "      <td>54.654737</td>\n",
       "      <td>54.654736</td>\n",
       "      <td>55.448204</td>\n",
       "      <td>55.448193</td>\n",
       "      <td>relu</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>uniform</td>\n",
       "      <td>linear</td>\n",
       "      <td>mae</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>1</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>100</td>\n",
       "      <td>46.275541</td>\n",
       "      <td>46.275524</td>\n",
       "      <td>46.596608</td>\n",
       "      <td>46.596607</td>\n",
       "      <td>relu</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>uniform</td>\n",
       "      <td>linear</td>\n",
       "      <td>mae</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>25</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>100</td>\n",
       "      <td>47.986740</td>\n",
       "      <td>47.986744</td>\n",
       "      <td>47.012429</td>\n",
       "      <td>47.012436</td>\n",
       "      <td>relu</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>uniform</td>\n",
       "      <td>linear</td>\n",
       "      <td>mae</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>50</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>100</td>\n",
       "      <td>47.161976</td>\n",
       "      <td>47.161983</td>\n",
       "      <td>46.790314</td>\n",
       "      <td>46.790306</td>\n",
       "      <td>relu</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>uniform</td>\n",
       "      <td>linear</td>\n",
       "      <td>mae</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>75</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>100</td>\n",
       "      <td>46.265337</td>\n",
       "      <td>46.265331</td>\n",
       "      <td>47.501382</td>\n",
       "      <td>47.501377</td>\n",
       "      <td>relu</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>uniform</td>\n",
       "      <td>linear</td>\n",
       "      <td>mae</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>100</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>100</td>\n",
       "      <td>46.289010</td>\n",
       "      <td>46.289009</td>\n",
       "      <td>47.208706</td>\n",
       "      <td>47.208702</td>\n",
       "      <td>relu</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>uniform</td>\n",
       "      <td>linear</td>\n",
       "      <td>mae</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>125</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>100</td>\n",
       "      <td>46.387451</td>\n",
       "      <td>46.387432</td>\n",
       "      <td>47.708837</td>\n",
       "      <td>47.708836</td>\n",
       "      <td>relu</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>uniform</td>\n",
       "      <td>linear</td>\n",
       "      <td>mae</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>150</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>100</td>\n",
       "      <td>54.656977</td>\n",
       "      <td>54.656979</td>\n",
       "      <td>55.451018</td>\n",
       "      <td>55.451000</td>\n",
       "      <td>relu</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>uniform</td>\n",
       "      <td>linear</td>\n",
       "      <td>mae</td>\n",
       "      <td>0.30000</td>\n",
       "      <td>1</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>100</td>\n",
       "      <td>48.802023</td>\n",
       "      <td>48.802013</td>\n",
       "      <td>47.340075</td>\n",
       "      <td>47.340076</td>\n",
       "      <td>relu</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>uniform</td>\n",
       "      <td>linear</td>\n",
       "      <td>mae</td>\n",
       "      <td>0.30000</td>\n",
       "      <td>25</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>100</td>\n",
       "      <td>46.145832</td>\n",
       "      <td>46.145840</td>\n",
       "      <td>47.023935</td>\n",
       "      <td>47.023933</td>\n",
       "      <td>relu</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>uniform</td>\n",
       "      <td>linear</td>\n",
       "      <td>mae</td>\n",
       "      <td>0.30000</td>\n",
       "      <td>50</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>100</td>\n",
       "      <td>46.777964</td>\n",
       "      <td>46.777954</td>\n",
       "      <td>47.240628</td>\n",
       "      <td>47.240608</td>\n",
       "      <td>relu</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>uniform</td>\n",
       "      <td>linear</td>\n",
       "      <td>mae</td>\n",
       "      <td>0.30000</td>\n",
       "      <td>75</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>100</td>\n",
       "      <td>46.651713</td>\n",
       "      <td>46.651711</td>\n",
       "      <td>47.235169</td>\n",
       "      <td>47.235161</td>\n",
       "      <td>relu</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>uniform</td>\n",
       "      <td>linear</td>\n",
       "      <td>mae</td>\n",
       "      <td>0.30000</td>\n",
       "      <td>100</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>100</td>\n",
       "      <td>46.352234</td>\n",
       "      <td>46.352242</td>\n",
       "      <td>46.927775</td>\n",
       "      <td>46.927761</td>\n",
       "      <td>relu</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>uniform</td>\n",
       "      <td>linear</td>\n",
       "      <td>mae</td>\n",
       "      <td>0.30000</td>\n",
       "      <td>125</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>100</td>\n",
       "      <td>46.375434</td>\n",
       "      <td>46.375458</td>\n",
       "      <td>47.316706</td>\n",
       "      <td>47.316704</td>\n",
       "      <td>relu</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>uniform</td>\n",
       "      <td>linear</td>\n",
       "      <td>mae</td>\n",
       "      <td>0.30000</td>\n",
       "      <td>150</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>100</td>\n",
       "      <td>54.657671</td>\n",
       "      <td>54.657673</td>\n",
       "      <td>55.452226</td>\n",
       "      <td>55.452209</td>\n",
       "      <td>relu</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>uniform</td>\n",
       "      <td>linear</td>\n",
       "      <td>mae</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>100</td>\n",
       "      <td>48.139853</td>\n",
       "      <td>48.139847</td>\n",
       "      <td>47.449405</td>\n",
       "      <td>47.449394</td>\n",
       "      <td>relu</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>uniform</td>\n",
       "      <td>linear</td>\n",
       "      <td>mae</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>25</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>100</td>\n",
       "      <td>47.044205</td>\n",
       "      <td>47.044205</td>\n",
       "      <td>47.102762</td>\n",
       "      <td>47.102764</td>\n",
       "      <td>relu</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>uniform</td>\n",
       "      <td>linear</td>\n",
       "      <td>mae</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>50</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>100</td>\n",
       "      <td>46.263532</td>\n",
       "      <td>46.263531</td>\n",
       "      <td>47.070473</td>\n",
       "      <td>47.070492</td>\n",
       "      <td>relu</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>uniform</td>\n",
       "      <td>linear</td>\n",
       "      <td>mae</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>75</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>100</td>\n",
       "      <td>46.241048</td>\n",
       "      <td>46.241051</td>\n",
       "      <td>46.908666</td>\n",
       "      <td>46.908676</td>\n",
       "      <td>relu</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>uniform</td>\n",
       "      <td>linear</td>\n",
       "      <td>mae</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>100</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>100</td>\n",
       "      <td>47.051173</td>\n",
       "      <td>47.051174</td>\n",
       "      <td>47.092768</td>\n",
       "      <td>47.092766</td>\n",
       "      <td>relu</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>uniform</td>\n",
       "      <td>linear</td>\n",
       "      <td>mae</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>125</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>100</td>\n",
       "      <td>46.608478</td>\n",
       "      <td>46.608475</td>\n",
       "      <td>47.512354</td>\n",
       "      <td>47.512371</td>\n",
       "      <td>relu</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>uniform</td>\n",
       "      <td>linear</td>\n",
       "      <td>mae</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>150</td>\n",
       "      <td>Adam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    round_epochs   val_loss    val_mae       loss        mae activation  \\\n",
       "0            100  54.658017  54.658028  55.451676  55.451672       relu   \n",
       "1            100  47.030283  47.030293  47.435449  47.435455       relu   \n",
       "2            100  46.621623  46.621613  47.053209  47.053215       relu   \n",
       "3            100  47.006439  47.006439  46.999699  46.999691       relu   \n",
       "4            100  46.342011  46.341999  47.275445  47.275444       relu   \n",
       "5            100  45.980314  45.980309  47.204249  47.204239       relu   \n",
       "6            100  46.357134  46.357128  46.871089  46.871086       relu   \n",
       "7            100  54.656627  54.656628  55.450429  55.450428       relu   \n",
       "8            100  46.864199  46.864208  47.167210  47.167206       relu   \n",
       "9            100  46.522723  46.522717  47.101156  47.101143       relu   \n",
       "10           100  47.086224  47.086224  47.139988  47.139999       relu   \n",
       "11           100  47.163597  47.163589  46.800133  46.800137       relu   \n",
       "12           100  46.608718  46.608711  47.031423  47.031422       relu   \n",
       "13           100  46.194201  46.194187  46.797180  46.797192       relu   \n",
       "14           100  54.660783  54.660763  55.454871  55.454868       relu   \n",
       "15           100  47.190145  47.190147  47.520032  47.520046       relu   \n",
       "16           100  47.591563  47.591564  47.440702  47.440701       relu   \n",
       "17           100  47.046996  47.046982  47.011675  47.011669       relu   \n",
       "18           100  46.411512  46.411503  47.047215  47.047218       relu   \n",
       "19           100  45.946016  45.946011  46.870604  46.870609       relu   \n",
       "20           100  46.237721  46.237732  47.270942  47.270962       relu   \n",
       "21           100  54.654737  54.654736  55.448204  55.448193       relu   \n",
       "22           100  46.275541  46.275524  46.596608  46.596607       relu   \n",
       "23           100  47.986740  47.986744  47.012429  47.012436       relu   \n",
       "24           100  47.161976  47.161983  46.790314  46.790306       relu   \n",
       "25           100  46.265337  46.265331  47.501382  47.501377       relu   \n",
       "26           100  46.289010  46.289009  47.208706  47.208702       relu   \n",
       "27           100  46.387451  46.387432  47.708837  47.708836       relu   \n",
       "28           100  54.656977  54.656979  55.451018  55.451000       relu   \n",
       "29           100  48.802023  48.802013  47.340075  47.340076       relu   \n",
       "30           100  46.145832  46.145840  47.023935  47.023933       relu   \n",
       "31           100  46.777964  46.777954  47.240628  47.240608       relu   \n",
       "32           100  46.651713  46.651711  47.235169  47.235161       relu   \n",
       "33           100  46.352234  46.352242  46.927775  46.927761       relu   \n",
       "34           100  46.375434  46.375458  47.316706  47.316704       relu   \n",
       "35           100  54.657671  54.657673  55.452226  55.452209       relu   \n",
       "36           100  48.139853  48.139847  47.449405  47.449394       relu   \n",
       "37           100  47.044205  47.044205  47.102762  47.102764       relu   \n",
       "38           100  46.263532  46.263531  47.070473  47.070492       relu   \n",
       "39           100  46.241048  46.241051  46.908666  46.908676       relu   \n",
       "40           100  47.051173  47.051174  47.092768  47.092766       relu   \n",
       "41           100  46.608478  46.608475  47.512354  47.512371       relu   \n",
       "\n",
       "    batch_size  dropout  epochs kernel_initializer last_activation losses  \\\n",
       "0           30        0     100            uniform          linear    mae   \n",
       "1           30        0     100            uniform          linear    mae   \n",
       "2           30        0     100            uniform          linear    mae   \n",
       "3           30        0     100            uniform          linear    mae   \n",
       "4           30        0     100            uniform          linear    mae   \n",
       "5           30        0     100            uniform          linear    mae   \n",
       "6           30        0     100            uniform          linear    mae   \n",
       "7           30        0     100            uniform          linear    mae   \n",
       "8           30        0     100            uniform          linear    mae   \n",
       "9           30        0     100            uniform          linear    mae   \n",
       "10          30        0     100            uniform          linear    mae   \n",
       "11          30        0     100            uniform          linear    mae   \n",
       "12          30        0     100            uniform          linear    mae   \n",
       "13          30        0     100            uniform          linear    mae   \n",
       "14          30        0     100            uniform          linear    mae   \n",
       "15          30        0     100            uniform          linear    mae   \n",
       "16          30        0     100            uniform          linear    mae   \n",
       "17          30        0     100            uniform          linear    mae   \n",
       "18          30        0     100            uniform          linear    mae   \n",
       "19          30        0     100            uniform          linear    mae   \n",
       "20          30        0     100            uniform          linear    mae   \n",
       "21          30        0     100            uniform          linear    mae   \n",
       "22          30        0     100            uniform          linear    mae   \n",
       "23          30        0     100            uniform          linear    mae   \n",
       "24          30        0     100            uniform          linear    mae   \n",
       "25          30        0     100            uniform          linear    mae   \n",
       "26          30        0     100            uniform          linear    mae   \n",
       "27          30        0     100            uniform          linear    mae   \n",
       "28          30        0     100            uniform          linear    mae   \n",
       "29          30        0     100            uniform          linear    mae   \n",
       "30          30        0     100            uniform          linear    mae   \n",
       "31          30        0     100            uniform          linear    mae   \n",
       "32          30        0     100            uniform          linear    mae   \n",
       "33          30        0     100            uniform          linear    mae   \n",
       "34          30        0     100            uniform          linear    mae   \n",
       "35          30        0     100            uniform          linear    mae   \n",
       "36          30        0     100            uniform          linear    mae   \n",
       "37          30        0     100            uniform          linear    mae   \n",
       "38          30        0     100            uniform          linear    mae   \n",
       "39          30        0     100            uniform          linear    mae   \n",
       "40          30        0     100            uniform          linear    mae   \n",
       "41          30        0     100            uniform          linear    mae   \n",
       "\n",
       "         lr  number_of_neurons optimizer  \n",
       "0   0.01000                  1      Adam  \n",
       "1   0.01000                 25      Adam  \n",
       "2   0.01000                 50      Adam  \n",
       "3   0.01000                 75      Adam  \n",
       "4   0.01000                100      Adam  \n",
       "5   0.01000                125      Adam  \n",
       "6   0.01000                150      Adam  \n",
       "7   0.00001                  1      Adam  \n",
       "8   0.00001                 25      Adam  \n",
       "9   0.00001                 50      Adam  \n",
       "10  0.00001                 75      Adam  \n",
       "11  0.00001                100      Adam  \n",
       "12  0.00001                125      Adam  \n",
       "13  0.00001                150      Adam  \n",
       "14  0.00010                  1      Adam  \n",
       "15  0.00010                 25      Adam  \n",
       "16  0.00010                 50      Adam  \n",
       "17  0.00010                 75      Adam  \n",
       "18  0.00010                100      Adam  \n",
       "19  0.00010                125      Adam  \n",
       "20  0.00010                150      Adam  \n",
       "21  0.00100                  1      Adam  \n",
       "22  0.00100                 25      Adam  \n",
       "23  0.00100                 50      Adam  \n",
       "24  0.00100                 75      Adam  \n",
       "25  0.00100                100      Adam  \n",
       "26  0.00100                125      Adam  \n",
       "27  0.00100                150      Adam  \n",
       "28  0.30000                  1      Adam  \n",
       "29  0.30000                 25      Adam  \n",
       "30  0.30000                 50      Adam  \n",
       "31  0.30000                 75      Adam  \n",
       "32  0.30000                100      Adam  \n",
       "33  0.30000                125      Adam  \n",
       "34  0.30000                150      Adam  \n",
       "35  1.00000                  1      Adam  \n",
       "36  1.00000                 25      Adam  \n",
       "37  1.00000                 50      Adam  \n",
       "38  1.00000                 75      Adam  \n",
       "39  1.00000                100      Adam  \n",
       "40  1.00000                125      Adam  \n",
       "41  1.00000                150      Adam  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyze_object = talos.Analyze(t)\n",
    "analyze_object.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45.9460161027365"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyze_object.low('val_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[50.358756180691934,\n",
       " 46.28023692582216,\n",
       " 44.37471552576703,\n",
       " 48.65706426716965,\n",
       " 48.70011535593421,\n",
       " 45.661485516984165,\n",
       " 44.889616350973306,\n",
       " 50.89818096606759,\n",
       " 44.74167027599068,\n",
       " 46.36972459930263]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e = talos.Evaluate(t)\n",
    "evaluation = e.evaluate(test_x, \n",
    "                        test_y, \n",
    "                        model_id=None, \n",
    "                        folds=10,\n",
    "                        shuffle=True, \n",
    "                        metric='val_loss', \n",
    "                        asc=True,\n",
    "                        task = \"continuous\")\n",
    "evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = talos.Predict(t)\n",
    "test_pred_y = p.predict(test_x, metric = 'val_loss', asc = True)\n",
    "\n",
    "#test_pred_y = normalizer.inverse_transform(test_pred_y)\n",
    "#test_y = normalizer.inverse_transform(test_y)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(16,12))\n",
    "plt.plot(test_y, color = 'red', label = 'Real pollution')\n",
    "plt.plot(test_pred_y, color = 'blue', label = 'Predictions')\n",
    "plt.title('Pollution forecast')\n",
    "plt.xlabel('Hours')\n",
    "plt.ylabel('Pollution value')\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
